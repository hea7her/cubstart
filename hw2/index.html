<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>LENS</title>
  <link rel="stylesheet" href="styles/index.css" />
</head>

<body>
  <div id="navbar">
    <a href="index.html">LENS</a>
    <a href="playground.html">Can You Tell?</a>
    <a href="bored.html">Resources</a>
  </div>
  <section id="about">
    <div class="description">
      <div class = "title">
      <h1>Welcome To LENS</h1>
    </div>
      <p>
        We are a simple, educational website developed by two girls who are passionate about 
        the development of ethical AI and its implications in the real world. 
        <br>
        <br>
        We are excited to learn with you!
      </p>
      <div class="description2">
      <h3>The Problem</h3>
      <p>
        In today’s world, AI and recommender systems serve a critical role in our daily lives. From the shows that 
        Netflix thinks we will like to the posts we like in our feeds, our media consumption is shaped by algorithms 
        that maximize engaging and interaction-worthy content. While these systems do keep things interesting, though, 
        they also come with flaws. The news and material that evoke the most interactions are often riddled with false 
        information; in general, we are much more likely to comment on a post that is inflammatory than one that is informative. 
        Because of this phenomenon, algorithms frequently promote content that is inaccurate, leading to widespread 
        misinformation.
        <br>
        <br>
      </div>

        <img class = "resize" src = "fakenews.jpeg" alt = "New York Times">
      </p>
      <h3>The Solution</h3>
      <p>
        To combat this pervasive issue, we’ll need a two-pronged approach:
        <br>
        <br>
        1. We must actively work with the developers of recommender systems. By reframing the way that these algorithms 
        work, we can counteract the unintended negative effects of interaction-based content sharing. 
        <br>
        <br>
        2. We must educate ourselves to catch misinformation when it occurs, by either doing additional research or 
        assessing the reliability of its source. This is where LENS steps in.
      </p>
      <img class = "resize" src = "fakethumbsdown.jpeg" alt = "University of Pennyslvania">
      <h3>How To Use LENS</h3>
      <p>
        LENS works against misinformation in two critical ways: 
        <br>
        <br>
        1. training the average consumer impacted by these systems to spot 
        misinformation
        <br>
        <br>
        2. directing them towards resources that will help them see past unreliable content
        
        <br>
        <br>
        If you navigate to 
        the 
        <a href = "http://127.0.0.1:5500/playground.html">Can You Tell?</a> section through the button at the top of the page, you’ll be directed to a quiz that gauges your 
        ability to check if content is accurate through your research or inspection skills. The Resources tab at the top will 
        also direct you to more information on the prevalence of misinformation and other research. We hope you enjoy! 
      </p>
    </div>
  </section>
</body>

</html>